{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom wordcloud import WordCloud\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Load the dataset\ndata_path = r\"C:\\Users\\subra\\Desktop\\Projects\\Oasis\\Stock_Market_Prediction\\data\\RedditNews.csv\"\ndf = pd.read_csv(data_path)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Display basic information about the dataset\nprint(\"First five rows of the dataset:\")\nprint(df.head())\n\nprint(\"\\nDataset information:\")\nprint(df.info())\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Check for missing values\nprint(\"\\nMissing values in the dataset:\")\nprint(df.isnull().sum())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Drop missing values if any\ndf.dropna(inplace=True)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Exploratory Data Analysis (EDA)\n# Word Cloud of Headlines\ntext = \" \".join(headline for headline in df['News'])\nwordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\nplt.figure(figsize=(10, 6))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.title(\"Word Cloud of News Headlines\")\nplt.show()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Check distribution of sentiment labels (if applicable)\nif 'Sentiment' in df.columns:\n    print(\"\\nDistribution of Sentiment Labels:\")\n    print(df['Sentiment'].value_counts())\n    sns.countplot(x='Sentiment', data=df, palette='viridis')\n    plt.title(\"Distribution of Sentiment Labels\")\n    plt.show()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Feature and target selection\nif 'Sentiment' in df.columns:\n    X = df['News']  # Features\n    y = df['Sentiment']  # Target (Sentiment labels like Positive, Negative, Neutral)\nelse:\n    print(\"\\nNo Sentiment column found. Assuming unsupervised learning or further analysis.\")\n    X = df['News']\n    y = None\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Text preprocessing and feature extraction\nvectorizer = CountVectorizer(stop_words='english', max_features=5000)\nX_vectorized = vectorizer.fit_transform(X)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Train-test split (if Sentiment column exists)\nif y is not None:\n    X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.3, random_state=42)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Train the model using Logistic Regression\n    model = LogisticRegression()\n    model.fit(X_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Make predictions\n    y_pred = model.predict(X_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Evaluate the model\n    print(\"\\nAccuracy of the model:\")\n    print(accuracy_score(y_test, y_pred))\n\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_test, y_pred))\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Confusion Matrix\n    conf_matrix = confusion_matrix(y_test, y_pred)\n    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)\n    plt.title(\"Confusion Matrix\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Unsupervised Learning or Analysis (if no Sentiment column)\nif y is None:\n    print(\"\\nPerforming Word Frequency Analysis:\")\n    word_freq = pd.DataFrame(vectorizer.get_feature_names_out(), columns=['Word'])\n    word_freq['Frequency'] = np.asarray(X_vectorized.sum(axis=0)).flatten()\n    word_freq = word_freq.sort_values(by='Frequency', ascending=False)\n    print(word_freq.head(20))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}